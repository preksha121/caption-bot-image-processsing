{"cells":[{"metadata":{},"cell_type":"markdown","source":"# "},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\ndf=pd.read_csv(\"../input/flickr8k-text/flickr8k.token.txt\",header=None,delimiter='\\n')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape\ndf[0][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"desc={}\nfor x in df[0]:\n        first,second=x.split('\\t')\n        img_name=first.split(\".\")[0]\n        \n        if desc.get(img_name) is None :\n            desc[img_name]= []\n                \n        desc[img_name].append(second)    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(desc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"desc[\"1000268201_693b08cb0e\"]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Text Cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\ndef clean_text(sentence):\n    sentence= sentence.lower()\n    sentence=re.sub(\"[^a-z]+\",\" \",sentence)\n    sentence=sentence.split()\n    \n    sentence= [s for s in sentence if len(s)>1]\n    sentence= \" \".join(sentence)\n    return sentence\n    \n    \n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clean_text(\"A cat is sitting on house # 4\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"dir(desc.items())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for key,caption_list in desc.items():\n    for i in range(len(caption_list)):\n        caption_list[i]=clean_text(caption_list[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"desc[\"1000268201_693b08cb0e\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating Vocab"},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(\"desc.txt\",\"w\") as f:\n    f.write(str(desc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\ndescriptions= {}\nwith open(\"desc.txt\",\"r\") as f:\n    descriptions=f.read()\njson_acceptable_string=descriptions.replace(\"'\",\"\\\"\")\ndescriptions=json.loads(json_acceptable_string)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(type(descriptions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dir(descriptions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab= set()\nfor key in descriptions.keys():\n    [vocab.update(sentence.split()) for sentence in descriptions[key]]\n    \nprint(\"Vocab Size: %d\"%len(vocab))    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_words=[]\nfor key in descriptions.keys():\n    [total_words.append(i) for des in descriptions[key] for i in des.split()]\n    \nprint(\"Total Words : %d\"%len(total_words))    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import collections\n\ncounter= collections.Counter(total_words)\nfreq_count = dict(counter)\nprint(len(freq_count.keys()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted_freq_count= sorted(freq_count.items(),reverse=True,key=lambda x: x[1])\n\nsorted_freq_count= [x for x in sorted_freq_count if x[1]>10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"sorted_freq_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_words=[x[0] for x in sorted_freq_count ]\nprint(len(total_words))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prepare train and test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_file= None\nwith open(\"../input/flickr8k-text/flickr_8k.trainImages.txt\",\"r\") as f:\n    train_data_file=f.read()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data_file=None\nwith open(\"../input/flickr8k-text/flickr_8k.testImages.txt\",\"r\") as f:\n    test_data_file=f.read()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_data_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=[row.split(\".\")[0] for row in train_data_file.split(\"\\n\")[:-1]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test=[row.split(\".\")[0] for row in test_data_file.split(\"\\n\")[:-1]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_descriptions={}\nfor img_id in train:\n    train_descriptions[img_id]=[]\n    for cap in descriptions[img_id]:\n        cap_to_append=\"startseq \" + cap + \" endseq\"\n        train_descriptions[img_id].append(cap_to_append)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Image Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.applications.resnet50 import ResNet50,preprocess_input","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model= ResNet50(weights=\"imagenet\",input_shape=(224,224,3))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"dir(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Model,load_model\nmodel_new= Model(model.input,model.layers[-2].output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.applications.resnet50 import preprocess_input\nfrom keras.preprocessing import image\nimport numpy as np\ndef preprocess_img(img):\n    img=image.load_img(img,target_size=(224,224))\n    img=image.img_to_array(img)\n    img=np.expand_dims(img,axis=0)\n    \n    img=preprocess_input(img)\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"\nIMG_PATH=\"../input/flickr8k/Images/\"\nimg= preprocess_img(IMG_PATH+\"1000268201_693b08cb0e.jpg\")\nplt.imshow(img[0])\nplt.show()\nprint(img)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"IMG_PATH=\"../input/flickr8k/Images/\"\nimport cv2\nimport matplotlib.pyplot as plt\n\nimg=cv2.imread(IMG_PATH+\"1000268201_693b08cb0e.jpg\")\nimg=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\nplt.imshow(img)\nplt.axis(\"off\")\nplt.show()\nprint(img)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Images to features"},{"metadata":{"trusted":true},"cell_type":"code","source":"def encode_image(img):\n    img= preprocess_img(img)\n    feature_vector= model_new.predict(img)\n    feature_vector=feature_vector.reshape((2048,))\n    #print(feature_vector.shape)\n    return feature_vector\n            \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encode_image(IMG_PATH+\"1000268201_693b08cb0e.jpg\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"from time import time\nstart = time()\nencoding_train = {}\n\nfor ix,img_id in enumerate(train):\n    img_path= IMG_PATH+ \"/\"+img_id+ \".jpg\"\n    encoding_train[img_id]=encode_image(img_path)\n    \n    if ix%100==0:\n        print(\"Encoding in progress Time Step %d\"%ix)\n        \nend_t= time()\nprint(\"Total time taken : \",end_t-start)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nwith open(\"encoded_train_features.pkl\",\"wb\") as f:\n    pickle.dump(encoding_train,f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"start = time()\nencoding_test = {}\n\nfor ix,img_id in enumerate(test):\n    img_path= IMG_PATH+ \"/\"+img_id+ \".jpg\"\n    encoding_test[img_id]=encode_image(img_path)\n    \n    if ix%100==0:\n        print(\"Encoding in progress Time Step %d\"%ix)\n        \nend_t= time()\nprint(\"Total time taken(test) : \",end_t-start)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(\"encoded_test_features.pkl\",\"wb\") as f:\n    pickle.dump(encoding_test,f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_to_idx={}\nidx_to_word={}\n\nfor i,word in enumerate(total_words):\n    word_to_idx[word]=i+1\n    idx_to_word[i+1]=word\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_to_idx[\"dog\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx_to_word[6]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(idx_to_word))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx_to_word[1846] ='startseq'\nword_to_idx['startseq']=1846\n\nidx_to_word[1847] ='endseq'\nword_to_idx['endseq']=1847\n\nvocab_size= len(word_to_idx)+ 1\nprint(\"VOCAB SIZE : \",vocab_size)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_len=0\nfor key in train_descriptions.keys():\n    for cap in train_descriptions[key]:\n        max_len=max(max_len,len(cap.split()))\n        \nprint(max_len)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Custom Data Loader"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import to_categorical \nfrom keras.preprocessing.sequence import pad_sequences\ndef data_generator(train_descriptions,encoding_train,word_to_idx,max_len,batch_size):\n    x1,x2,y=[],[],[]\n    \n    \n    n=0\n    while True:\n        for key,desc_list in train_descriptions.items():\n            n+=1\n            \n            photo = encoding_train[key]\n            for desc in desc_list:\n                \n                seq=[word_to_idx[word] for word in desc.split() if word in word_to_idx]\n                for i in range(1,len(seq)):\n                    xi= seq[0:i]\n                    yi= seq[i]\n                    \n                    xi=pad_sequences([xi],maxlen=max_len,value=0,padding='post')[0]\n                    yi=to_categorical([yi],num_classes=vocab_size)[0]\n                    \n                    x1.append(photo)\n                    x2.append(xi)\n                    y.append(yi)\n                    \n                    \n                if n==batch_size:\n                    yield([np.array(x1),np.array(x2)],np.array(y))\n                    x1,x2,y= [],[],[]\n                    n=0\n                    \n            \n            ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Word embedding using glove6B50D"},{"metadata":{"trusted":true},"cell_type":"code","source":"f = open(\"../input/glove6b50d/glove.6B.50d.txt\",encoding='utf8')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_index= {}\n\nfor line in f:\n    values = line.split()\n    \n    word= values[0]\n    word_embedding= np.array(values[1:],dtype='float')\n    embedding_index[word]= word_embedding","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_index['apple']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_embedding_matrix():\n    emb_dim=50\n    matrix=np.zeros((vocab_size,emb_dim))\n    for word,idx in word_to_idx.items():\n        embedding_vector = embedding_index.get(word)\n        \n        if embedding_vector is not None:\n            matrix[idx]=embedding_vector\n            \n    return matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_matrix= get_embedding_matrix()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Implementation"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Input,Dense,Dropout,Embedding,LSTM\nfrom keras.layers.merge import add\ninput_img_features = Input(shape=(2048,))\ninp_img1 = Dropout(0.3)(input_img_features)\ninp_img2= Dense(256,activation='relu')(inp_img1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_captions= Input(shape=(max_len,))\ninp_cap1 = Embedding(input_dim=vocab_size,output_dim=50,mask_zero=True)(input_captions)\ninp_cap2= Dropout(0.3)(inp_cap1)\ninp_cap3= LSTM(256)(inp_cap2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"from keras.applications.resnet50 import decode_predictions\ndecoder1= add([inp_img2,inp_cap3])\ndecoder2= Dense(256,activation='relu')(decoder1)\noutputs= Dense(vocab_size,activation='softmax')(decoder2)\n\nmodel = Model(inputs=[input_img_features,input_captions],outputs=outputs)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.layers[2].set_weights([embedding_matrix])\nmodel.layers[2].trainable=False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',optimizer='adam')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs=20\nbatch_size=3\nsteps=len(train_descriptions)//batch_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train():\n    \n    \n    for i in range(epochs):\n        generator =data_generator(train_descriptions,encoding_train,word_to_idx,max_len,batch_size)\n        model.fit(generator,epochs=1,steps_per_epoch=steps,verbose=1)\n        model.save('./model_weights/model_'+str(i)+'.h5')\n        \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"train()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"load_model('./model_weights/model_9.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_caption(photo):\n    in_text=\"startseq\"\n    for i in range(max_len):\n        sequence = [word_to_idx[w] for w in in_text.split() if w in word_to_idx]\n        sequence = pad_sequences([sequence],maxlen=max_len,padding='post')\n        \n        ypred= model.predict([photo,sequence])\n        ypred = ypred.argmax() # word with max prob always-Greedy sampling\n        word= idx_to_word[ypred]\n        in_text +=(' ' +word)\n        \n        if word== 'endseq':\n            break\n            \n    final_caption =in_text.split()[1:-1]\n    final_caption =' '.join(final_caption)\n    return final_caption\n        \n        \n        \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pick some random images and see Results\n\n\nfor i in range(15):\n    idx = np.random.randint(0,1000)\n    all_img_names = list(encoding_test.keys())\n    img_name =all_img_names[idx]\n    photo_2048 = encoding_test[img_name].reshape((1,2048))\n    \n    i= plt.imread(IMG_PATH+img_name+\".jpg\")\n    caption= predict_caption(photo_2048)\n    print(caption)\n    plt.imshow(i)\n    plt.axis('off')\n    plt.show()\n    \n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}